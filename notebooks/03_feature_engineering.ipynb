{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 3: Feature Engineering\n",
                "## Step 3.1: Price Action Features\n",
                "In this step, we derive features directly from the OHLCV (Open, High, Low, Close, Volume) data to capture market dynamics.\n",
                "\n",
                "### Features to Implement:\n",
                "1. **Candle Body:** Size and direction (`close - open`).\n",
                "2. **Wicks:**\n",
                "   - **Upper Wick:** `high - max(open, close)`\n",
                "   - **Lower Wick:** `min(open, close) - low`\n",
                "3. **Price Ratios:**\n",
                "   - `close / open` (Daily return proxy)\n",
                "   - `high / low` (Intraday volatility)\n",
                "   - `close / high` (Strength near highs)\n",
                "   - `close / low` (Strength near lows)\n",
                "4. **Entry Price Context:** (`close` vs `entry_price` if available)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "\n",
                "# Add project root to path\n",
                "project_root = Path('../').resolve()\n",
                "sys.path.append(str(project_root))\n",
                "\n",
                "from config import PROCESSED_DATA_DIR\n",
                "\n",
                "# Set Plotting Style\n",
                "sns.set_style(\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "print(\"âœ… Libraries Loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Quality-Checked Data\n",
                "data_path = PROCESSED_DATA_DIR / \"step1_quality_checked.csv\"\n",
                "\n",
                "try:\n",
                "    df = pd.read_csv(data_path)\n",
                "    print(f\"âœ… Loaded Dataset from: {data_path}\")\n",
                "    print(f\"Shape: {df.shape}\")\n",
                "except FileNotFoundError:\n",
                "    print(f\"âŒ File not found: {data_path}. Please complete Phase 1 first.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. Candle Properties ---\n",
                "# Body Size (Absolute)\n",
                "df['candle_body'] = df['close'] - df['open']\n",
                "\n",
                "# Body Size (%)\n",
                "df['candle_body_pct'] = (df['close'] - df['open']) / df['open']\n",
                "\n",
                "# Upper Wick\n",
                "df['upper_wick'] = df['high'] - df[['open', 'close']].max(axis=1)\n",
                "\n",
                "# Lower Wick\n",
                "df['lower_wick'] = df[['open', 'close']].min(axis=1) - df['low']\n",
                "\n",
                "# Wick Ratio (Upper / Lower) - Handle division by zero\n",
                "df['wick_ratio'] = df['upper_wick'] / (df['lower_wick'] + 1e-9)\n",
                "\n",
                "# Total Range (High - Low)\n",
                "df['candle_range'] = df['high'] - df['low']\n",
                "\n",
                "# --- 2. Price Ratios ---\n",
                "df['ratio_close_open'] = df['close'] / df['open']\n",
                "df['ratio_high_low'] = df['high'] / df['low']\n",
                "df['ratio_close_high'] = df['close'] / df['high']\n",
                "df['ratio_close_low'] = df['close'] / df['low']\n",
                "\n",
                "# --- 3. Entry Price Context (User Feature) ---\n",
                "if 'entry_price' in df.columns:\n",
                "    df['price_move_ratio'] = (df['close'] - df['entry_price']) / df['entry_price']\n",
                "    print(\"âœ… Added 'price_move_ratio' based on entry_price.\")\n",
                "else:\n",
                "    print(\"â„¹ï¸ 'entry_price' column not found, skipping price_move_ratio.\")\n",
                "\n",
                "print(\"âœ… Price Action Features calculation complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3.2: Volatility Features\n",
                "Volatility is a key driver for trading signals. We will implement:\n",
                "1. **Rolling Statistics:** Mean and Standard Deviation for different windows (7, 14, 50).\n",
                "2. **Bollinger Bands:** 20-period moving average +/- 2 standard deviations.\n",
                "3. **ATR (Average True Range):** Measure of market volatility.\n",
                "4. **Percentage Range:** (High - Low) relative to Close."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Windows\n",
                "windows = [7, 14, 50]\n",
                "\n",
                "# 1. Rolling Statistics (Mean & Std)\n",
                "for w in windows:\n",
                "    df[f'rolling_mean_{w}'] = df['close'].rolling(window=w).mean()\n",
                "    df[f'rolling_std_{w}'] = df['close'].rolling(window=w).std()\n",
                "    \n",
                "    # Normalized Deviation: (Close - Mean) / Std\n",
                "    # This indicates how many standard deviations the price is away from the mean (Z-Score concept)\n",
                "    df[f'z_score_{w}'] = (df['close'] - df[f'rolling_mean_{w}']) / (df[f'rolling_std_{w}'] + 1e-9)\n",
                "\n",
                "print(f\"âœ… Rolling Mean/Std/Z-Score created for windows: {windows}\")\n",
                "\n",
                "# 2. Bollinger Bands (20, 2)\n",
                "bb_window = 20\n",
                "bb_std = 2\n",
                "df['bb_middle'] = df['close'].rolling(window=bb_window).mean()\n",
                "df['bb_upper'] = df['bb_middle'] + (df['close'].rolling(window=bb_window).std() * bb_std)\n",
                "df['bb_lower'] = df['bb_middle'] - (df['close'].rolling(window=bb_window).std() * bb_std)\n",
                "\n",
                "# BB Width: (Upper - Lower) / Middle -> Normalized measure of volatility\n",
                "df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']\n",
                "\n",
                "# %B: (Close - Lower) / (Upper - Lower) -> Position of price within the bands\n",
                "df['bb_pct_b'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-9)\n",
                "\n",
                "# 3. Average True Range (ATR)\n",
                "def calculate_atr(high, low, close, window=14):\n",
                "    # True Range is max of: (High - Low), |High - PrevClose|, |Low - PrevClose|\n",
                "    tr1 = high - low\n",
                "    tr2 = (high - close.shift(1)).abs()\n",
                "    tr3 = (low - close.shift(1)).abs()\n",
                "    \n",
                "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
                "    atr = tr.rolling(window=window).mean()\n",
                "    return atr\n",
                "\n",
                "df['atr_14'] = calculate_atr(df['high'], df['low'], df['close'], window=14)\n",
                "df['atr_pct'] = df['atr_14'] / df['close']\n",
                "\n",
                "# --- Handle NaN Values (Clean Start) ---\n",
                "# Drop rows where rolling windows haven't filled yet (using max window 50)\n",
                "initial_len = len(df)\n",
                "df.dropna(subset=['rolling_std_50', 'bb_upper', 'atr_14'], inplace=True)\n",
                "print(f\"âœ… Dropped initial NaN rows. Rows removed: {initial_len - len(df)}\")\n",
                "print(\"âœ… Volatility Features created.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3.3: Momentum Features\n",
                "Momentum indicators help identify the speed of price movement. We will implement:\n",
                "1. **RSI Slope:** The rate of change of RSI (`RSI - RSI.shift(1)`).\n",
                "2. **MACD:** Moving Average Convergence Divergence.\n",
                "3. **ROC (Rate of Change):** Percentage change in price over `n` periods.\n",
                "4. **Interaction Features:** Combining Momentum and Volatility (e.g., `RSI * BB_Width`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure RSI exists (from Phase 1). If not, calculate it.\n",
                "def calculate_rsi(close, window=14):\n",
                "    delta = close.diff()\n",
                "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
                "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
                "    rs = gain / (loss + 1e-9)\n",
                "    return 100 - (100 / (1 + rs))\n",
                "\n",
                "if 'RSI' not in df.columns:\n",
                "    print(\"â„¹ï¸ RSI not found, calculating it now...\")\n",
                "    df['RSI'] = calculate_rsi(df['close'])\n",
                "else:\n",
                "    print(\"âœ… RSI already exists.\")\n",
                "\n",
                "# 1. RSI Slope (Momentum of Momentum)\n",
                "df['rsi_slope'] = df['RSI'].diff()\n",
                "df['rsi_slope_3'] = df['RSI'].diff(3) # 3-period slope\n",
                "\n",
                "# 2. MACD (12, 26, 9)\n",
                "exp1 = df['close'].ewm(span=12, adjust=False).mean()\n",
                "exp2 = df['close'].ewm(span=26, adjust=False).mean()\n",
                "df['macd'] = exp1 - exp2\n",
                "df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
                "df['macd_hist'] = df['macd'] - df['macd_signal']\n",
                "\n",
                "# 3. ROC (Rate of Change) - 7, 14 periods\n",
                "for n in [7, 14]:\n",
                "    df[f'roc_{n}'] = df['close'].pct_change(periods=n) * 100\n",
                "\n",
                "# 4. Interaction Features\n",
                "# Combining Volatility and Momentum\n",
                "df['rsi_x_vol'] = df['RSI'] * df['bb_width']  # High RSI + High Volatility = Strong Move?\n",
                "df['macd_x_vol'] = df['macd_hist'] * df['atr_pct'] # Strong MACD + High ATR\n",
                "\n",
                "print(\"âœ… Momentum Features (RSI Slope, MACD, ROC) created.\")\n",
                "print(\"âœ… Interaction Features created.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3.4: Feature Selection & Redundancy Check\n",
                "To ensure efficient modeling, we must remove highly collinear features. Extremely high correlation (> 0.95) between features adds redundancy without adding information and can destabilize some models.\n",
                "\n",
                "### Strategy:\n",
                "1. Calculate the Feature-Feature Correlation Matrix.\n",
                "2. Identify pairs with Correlation > 0.95.\n",
                "3. From each pair, drop the feature with the **lower correlation to the target** (if available), or drop one arbitrarily."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select only numeric columns for correlation\n",
                "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
                "exclude_cols = ['target_hit', 'stop_hit', 'target_type', 'hit_first', 'Unnamed: 0'] # Exclude non-features\n",
                "feature_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
                "\n",
                "print(f\"Initial Feature Count: {len(feature_cols)}\")\n",
                "\n",
                "# Calculate Correlation Matrix\n",
                "corr_matrix = df[feature_cols].corr().abs()\n",
                "\n",
                "# Select upper triangle of correlation matrix\n",
                "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
                "\n",
                "# Find features with correlation > 0.95\n",
                "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
                "\n",
                "print(f\"âš ï¸ Highly Correlated Features to Drop (>0.95): {len(to_drop)}\")\n",
                "\n",
                "# Refined Drop Strategy: Keep the one better correlated with Target\n",
                "if 'target_hit' in df.columns:\n",
                "    final_drop_list = []\n",
                "    target_corr = df[feature_cols].corrwith(df['target_hit']).abs()\n",
                "    \n",
                "    for col in to_drop:\n",
                "        # Find the feature it is correlated with\n",
                "        correlated_with = upper.index[upper[col] > 0.95].tolist()\n",
                "        \n",
                "        for other_col in correlated_with:\n",
                "            # Compare target correlations\n",
                "            score_current = target_corr.get(col, 0)\n",
                "            score_other = target_corr.get(other_col, 0)\n",
                "            \n",
                "            # Logic: We want to DROP the one with LOWER score\n",
                "            if score_current < score_other:\n",
                "                final_drop_list.append(col)\n",
                "            else:\n",
                "                final_drop_list.append(other_col)\n",
                "else:\n",
                "    final_drop_list = to_drop\n",
                "\n",
                "# --- Prevent Duplicates in Drop List (User Feedback) ---\n",
                "final_drop_list = list(set(final_drop_list))\n",
                "\n",
                "print(f\"\\nðŸ”¥ Final List of Features to Drop: {len(final_drop_list)}\")\n",
                "print(final_drop_list)\n",
                "\n",
                "# Drop them\n",
                "df_engineered = df.drop(columns=final_drop_list)\n",
                "print(f\"\\nâœ… Dropped redundant features. New Shape: {df_engineered.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Final Logging Summary (User Feedback) ---\n",
                "print(\"\\nðŸ“Š Feature counts by group:\")\n",
                "print(f\"Price Action:  {len([c for c in df_engineered.columns if 'candle' in c or 'ratio_' in c or 'wick' in c])}\")\n",
                "print(f\"Volatility:    {len([c for c in df_engineered.columns if 'rolling_' in c or 'bb_' in c or 'atr' in c or 'z_score' in c])}\")\n",
                "print(f\"Momentum:      {len([c for c in df_engineered.columns if 'rsi' in c or 'macd' in c or 'roc_' in c])}\")\n",
                "print(f\"Total Features: {len(df_engineered.columns)}\")\n",
                "\n",
                "# --- Save Final Engineered Data ---\n",
                "output_path = PROCESSED_DATA_DIR / \"step3_features_engineered.csv\"\n",
                "df_engineered.to_csv(output_path, index=False)\n",
                "\n",
                "print(f\"\\nðŸ’¾ Saved Final Engineered Dataset to: {output_path}\")\n",
                "print(\"âœ… Phase 3 Refined & Complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}